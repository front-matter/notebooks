<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>https://front-matter.io/</id><title>Popular bioinformatics preprints posted in the last week</title><updated>2021-11-22T12:05:39.929850+00:00</updated><author><name>Martin Fenner</name><email>martin@front-matter.io</email></author><link href="https://front-matter.io" rel="alternate"/><link href="https://front-matter.io/bioinformatics/feed.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="0.9.0">python-feedgen</generator><entry><id>https://doi.org/10.1101/2021.11.15.468676</id><title>Built on sand: the shaky foundations of simulating single-cell RNA sequencing data (70 tweets)</title><updated>2021-11-22T12:05:39.953326+00:00</updated><author><name>Helena L. Crowell</name></author><author><name>Sarah X. Morillo Leonardo</name></author><author><name>Charlotte Soneson</name></author><author><name>Mark D. Robinson</name></author><content>&lt;p&gt;With the emergence of hundreds of single-cell RNA-sequencing (scRNA-seq) datasets, the number of computational tools to analyse aspects of the generated data has grown rapidly. As a result, there is a recurring need to demonstrate whether newly developed methods are truly performant â€“ on their own as well as in comparison to existing tools. Benchmark studies aim to consolidate the space of available methods for a given task, and often use simulated data that provide a ground truth for evaluations. Thus, demanding a high quality standard for synthetically generated data is critical to make simulation study results credible and transferable to real data.&lt;/p&gt;&lt;p&gt;Here, we evaluated methods for synthetic scRNA-seq data generation in their ability to mimic experimental data. Besides comparing gene- and cell-level quality control summaries in both one- and two-dimensional settings, we further quantified these at the batch- and cluster-level. Secondly, we investigate the effect of simulators on clustering and batch correction method comparisons, and, thirdly, which and to what extent quality control summaries can capture reference-simulation similarity.&lt;/p&gt;&lt;p&gt;Our results suggest that most simulators are unable to accommodate complex designs without introducing artificial effects; they yield over-optimistic performance of integration, and potentially unreliable ranking of clustering methods; and, it is generally unknown which summaries are important to ensure effective simulation-based method comparisons.&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.11.15.468676" rel="alternate" title="Built on sand: the shaky foundations of simulating single-cell RNA sequencing data (70 tweets)"/><category term="Bioinformatics"/><published>2021-11-15T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.11.18.469072</id><title>scCODE: an R package for personalized differentially expressed gene detection on single-cell RNA-sequencing data (24 tweets)</title><updated>2021-11-22T12:05:39.953545+00:00</updated><author><name>jiawei Zou</name></author><author><name>miaochen Wang</name></author><author><name>zhen Zhang</name></author><author><name>zheqi Liu</name></author><author><name>xiaobin Zhang</name></author><author><name>rong Hua</name></author><author><name>ke Chen</name></author><author><name>xin Zou</name></author><author><name>Jie Hao</name></author><content>&lt;p&gt;Differential expression (DE) gene detection in single-cell RNA-seq (scRNA-seq) data is a key step to understand the biological question investigated. We find that DE methods together with gene filtering have profound impact on DE gene identification, and different datasets will benefit from personalized DE gene detection strategies. Existing tools don't take gene filtering into consideration, and couldn't evaluate DE performance on real datasets without prior knowledge of true results. Based on two new metrics, we propose scCODE (single cell Consensus Optimization of Differentially Expressed gene detection), an R package to automatically optimize DE gene detection for each experimental scRNA-seq dataset.&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.11.18.469072" rel="alternate" title="scCODE: an R package for personalized differentially expressed gene detection on single-cell RNA-sequencing data (24 tweets)"/><category term="Bioinformatics"/><published>2021-11-19T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.11.18.468666</id><title>PURC v2.0: a program for improved sequence inference for polyploid phylogenetics and other manifestations of the multiple-copy problem (23 tweets)</title><updated>2021-11-22T12:05:39.953713+00:00</updated><author><name>Peter W Schafran</name></author><author><name>Fay-Wei W Li</name></author><author><name>Carl Rothfels</name></author><content>&lt;p&gt;Inferring the true biological sequences from  amplicon mixtures remains a difficult bioinformatic problem. The traditional approach is to cluster  sequencing reads by similarity thresholds and treat the consensus sequence of each cluster as an "operational taxonomic unit" (OTU). Recently, this approach has been improved upon by model-based methods that correct PCR and sequencing errors in  order to infer "amplicon sequence variants"  (ASVs). To date, ASV approaches have been used primarily in metagenomics, but they are also useful for identifying allelic or paralogous variants and  for determining homeologs in polyploid organisms. To facilitate the usage of ASV methods among polyploidy researchers, we incorporated ASV inference alongside OTU clustering in PURC v2.0, a major update to PURC (Pipeline for Untangling Reticulate Complexes). In addition to preserving original PURC functions, PURC v2.0 allows users to process PacBio CCS/HiFi reads through DADA2 to generate and annotate ASVs for multiplexed data, with outputs including separate alignments for each locus ready for phylogenetic inference. In addition, PURC v2.0 features faster demultiplexing than the original version and has been updated to be compatible with Python 3. In this chapter we present results indicating that PURC v2.0 (using the ASV approach) is more likely to infer the correct biological sequences in comparison to the earlier OTU-based PURC, and describe how to prepare sequencing data, run PURC v2.0 under several different modes, and interpret the output. We  expect that PURC v2.0 will provide biologists with  a method for generating multi-locus "moderate data" datasets that are large enough to be phylogenetically informative and small enough for manual curation.&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.11.18.468666" rel="alternate" title="PURC v2.0: a program for improved sequence inference for polyploid phylogenetics and other manifestations of the multiple-copy problem (23 tweets)"/><category term="Bioinformatics"/><published>2021-11-19T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.11.18.469186</id><title>TCR-BERT: learning the grammar of T-cell receptors for flexible antigen- binding analyses (20 tweets)</title><updated>2021-11-22T12:05:39.953838+00:00</updated><author><name>Kevin E. Wu</name></author><author><name>Kathryn E. Yost</name></author><author><name>Bence Daniel</name></author><author><name>Julia A Belk</name></author><author><name>Yu Xia</name></author><author><name>Takeshi Egawa</name></author><author><name>Ansuman Satpathy</name></author><author><name>Howard Chang</name></author><author><name>James Zou</name></author><content>&lt;p&gt;The T-cell receptor (TCR) allows T-cells to recognize and respond to antigens presented by infected and diseased cells. However, due to TCRs' staggering diversity and the complex binding dynamics underlying TCR antigen recognition, it is challenging to predict which antigens a given TCR may bind to. Here, we present TCR-BERT, a deep learning model that applies self-supervised transfer learning to this problem. TCR-BERT leverages unlabeled TCR sequences to learn a general, versatile representation of TCR sequences, enabling numerous downstream applications. We demonstrate that TCR-BERT can be used to build state-of-the-art TCR-antigen binding predictors with improved generalizability compared to prior methods. TCR-BERT simultaneously facilitates clustering sequences likely to share antigen specificities. It also facilitates computational approaches to challenging, unsolved problems such as designing novel TCR sequences with engineered binding affinities. Importantly, TCR-BERT enables all these advances by focusing on residues with known biological significance. TCR-BERT can be a useful tool for T-cell scientists, enabling greater understanding and more diverse applications, and provides a conceptual framework for leveraging unlabeled data to improve machine learning on biological sequences.&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.11.18.469186" rel="alternate" title="TCR-BERT: learning the grammar of T-cell receptors for flexible antigen- binding analyses (20 tweets)"/><category term="Bioinformatics"/><published>2021-11-20T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.11.18.469017</id><title>ZARP: An automated workflow for processing of RNA-seq data (16 tweets)</title><updated>2021-11-22T12:05:39.953997+00:00</updated><author><name>Maria Katsantoni</name></author><author><name>Foivos Gypas</name></author><author><name>Christina J. Herrmann</name></author><author><name>Dominik Burri</name></author><author><name>Maciej Bak</name></author><author><name>Paula Iborra</name></author><author><name>Krish Agarwal</name></author><author><name>Meric Ataman</name></author><author><name>Anastasiya Boersch</name></author><author><name>Mihaela Zavolan</name></author><author><name>Alexander Kanitz</name></author><content>&lt;p&gt;RNA sequencing (RNA-seq) is a crucial technique for many scientific studies and multiple models, and software packages have been developed for the processing and analysis of such data. Given the plethora of available tools, choosing the most appropriate ones is a time-consuming process that requires an in-depth understanding of the data, as well as of the principles and parameters of each tool. In addition, packages designed for individual tasks are developed in different programming languages and have dependencies of various degrees of complexity, which renders their installation and execution challenging for users with limited computational expertise. The use of workflow languages and execution engines with support for virtualization and encapsulation options such as containers and Conda environments facilitates these tasks considerably. Computational workflows defined in those languages can be reliably shared with the scientific community, enhancing reusability, while improving reproducibility of results by making individual analysis steps more transparent. Here we present ZARP, a general purpose RNA-seq analysis workflow which builds on state-of-the-art software in the field to facilitate the analysis of RNA-seq data sets. ZARP is developed in the Snakemake workflow language using best software development practices. It can run locally or in a cluster environment, generating extensive reports not only of the data but also of the options utilized. It is built using modern technologies with the ultimate goal to reduce the hands-on time for bioinformaticians and non-expert users. ZARP is available under a permissive Open Source license and open to contributions by the scientific community.&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.11.18.469017" rel="alternate" title="ZARP: An automated workflow for processing of RNA-seq data (16 tweets)"/><category term="Bioinformatics"/><published>2021-11-19T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.11.18.469113</id><title>STRling: a k-mer counting approach that detects short tandem repeat expansions at known and novel loci (13 tweets)</title><updated>2021-11-22T12:05:39.954168+00:00</updated><author><name>Harriet Dashnow</name></author><author><name>Brent S. Pedersen</name></author><author><name>Laurel Hiatt</name></author><author><name>Joe Brown</name></author><author><name>Sarah J. Beecroft</name></author><author><name>Gianina Ravenscroft</name></author><author><name>Amy J. LaCroix</name></author><author><name>Phillipa Lamont</name></author><author><name>Richard H. Roxburgh</name></author><author><name>Miriam J. Rodrigues</name></author><author><name>Mark Davis</name></author><author><name>Heather C. Mefford</name></author><author><name>Nigel G. Laing</name></author><author><name>Aaron R. Quinlan</name></author><content>&lt;p&gt;Expansions of short tandem repeats (STRs) cause dozens of rare Mendelian diseases. However, STR expansions, especially those arising from repeats not present in the reference genome, are challenging to detect from short-read sequencing data. Such "novel" STRs include new repeat units occurring at known STR loci, or entirely new STR loci where the sequence is absent from the reference genome. A primary cause of difficulty detecting STR expansions is that reads arising from STR expansions are frequently mismapped or unmapped. To address this challenge, we have developed STRling, a new STR detection algorithm that counts k-mers (short DNA sequences of length k) in DNA sequencing reads, to efficiently recover reads that inform the presence and size of STR expansions. As a result, STRling can call expansions at both known and novel STR loci. STRling has a sensitivity of 83% for 14 known STR disease loci, including the novel STRs that cause CANVAS and DBQD2. It is the first method to resolve the position of novel STR expansions to base pair accuracy. Such accuracy is essential to interpreting the consequence of each expansion. STRling has an estimated 0.078 false discovery rate for known pathogenic loci in unaffected individuals and a 0.20 false discovery rate for genome-wide loci in unaffected individuals when using variants called from long-read data as truth. STRling is fast, scalable on cloud computing, open-source, and freely available at https://github.com/quinlan-lab/STRling.&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.11.18.469113" rel="alternate" title="STRling: a k-mer counting approach that detects short tandem repeat expansions at known and novel loci (13 tweets)"/><category term="Bioinformatics"/><published>2021-11-20T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.11.16.468904</id><title>VIVID: a web application for variant interpretation and visualisation in multidimensional analyses (13 tweets)</title><updated>2021-11-22T12:05:39.954353+00:00</updated><author><name>Swapnil Tichkule</name></author><author><name>Yoochan Myung</name></author><author><name>Myo T Naung</name></author><author><name>Brendan RE Ansell</name></author><author><name>Andrew Guy</name></author><author><name>Namrata Srivastava</name></author><author><name>Somya Mehra</name></author><author><name>Simone M Caccio</name></author><author><name>Ivo Mueller</name></author><author><name>Alyssa E Barry</name></author><author><name>Cock van Oosterhout</name></author><author><name>Bernard Pope</name></author><author><name>David B Ascher</name></author><author><name>Aaron Jex</name></author><content>&lt;p&gt;Large-scale comparative genomics- and population genetic studies generate enormous amounts of polymorphism data in the form of DNA variants. Ultimately, the goal of many of these studies is to associate genetic variants to phenotypes or fitness. We introduce VIVID, an interactive, user-friendly web application that integrates a wide range of approaches for encoding genotypic to phenotypic information in any organism or disease, from an individual or population, in three-dimensional (3D) space. It allows mutation mapping and annotation, calculation of interactions and conservation scores, prediction of harmful effects, analysis of diversity and selection, and 3-dimensional (3D) visualisation of genotypic information encoded in Variant Call Format (VCF) on AlphaFold2 protein models. VIVID enables the rapid assessment of genes of interest in the study of adaptive evolution and the genetic load, and it helps prioritising targets for experimental validation. We demonstrate the utility of VIVID by exploring the evolutionary genetics of the parasitic protist Plasmodium falciparum, revealing geographic variation in the signature of balancing selection in potential targets of functional antibodies.&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.11.16.468904" rel="alternate" title="VIVID: a web application for variant interpretation and visualisation in multidimensional analyses (13 tweets)"/><category term="Bioinformatics"/><published>2021-11-19T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.11.20.469412</id><title>Artificial Intelligence uncovers carcinogenic human metabolites (11 tweets)</title><updated>2021-11-22T12:05:39.955219+00:00</updated><author><name>Aayushi Mittal</name></author><author><name>Vishakha Gautam</name></author><author><name>Roshan S</name></author><author><name>Sakshi Arora</name></author><author><name>Sheetanshu Saproo</name></author><author><name>Ria Gupta</name></author><author><name>Sanjay Kumar Mohanty</name></author><author><name>Prakriti Garg</name></author><author><name>Anmol Aggarwal</name></author><author><name>Padmasini R</name></author><author><name>Nilesh Kumar Dixit</name></author><author><name>Vijay Pal Singh</name></author><author><name>Anurag Mehta</name></author><author><name>Juhi Tayal</name></author><author><name>Srivatsava Naidu</name></author><author><name>Debarka Sengupta</name></author><author><name>Gaurav Ahuja</name></author><content>&lt;p&gt;The genome of a eukaryotic cell is often vulnerable to both intrinsic and extrinsic threats due to its constant exposure to a myriad of heterogeneous chemical compounds. Despite the availability of innate DNA damage repair pathways, some genomic lesions trigger cells for malignant transformation. Accurate prediction of carcinogens is an ever-challenging task due to the limited information about bonafide (non)carcinogens. This, in turn, constrains the generalisability of such models. We developed a novel ensemble classifier (Metabokiller) that accurately recognizes carcinogens by quantitatively assessing their chemical composition as well as potential to induce proliferation, oxidative stress, genotoxicity, alterations in epigenetic signatures, and activation of anti-apoptotic pathways, therefore obviates the need for bonafide (non)carcinogens for training model. Concomitant with the carcinogenicity prediction, it also reveals the contribution of the aforementioned biochemical processes in carcinogenicity, thereby making the proposed approach highly interpretable. Metabokiller outwits existing best practice methods for the carcinogenicity prediction task. We used Metabokiller to decode the cellular endogenous metabolic threats by screening a large pool of human metabolites and identified putative metabolites that could potentially trigger malignancy in normal cells. To cross-validate our predictions, we performed an array of functional assays and genome-wide transcriptome analysis on two Metabokiller-flagged, and previously uncharacterized human metabolites by using Saccharomyces cerevisiae as a model organism and observed larger synergy with the prediction probabilities. Finally, the carcinogenicity potential of these metabolites was evaluated using a malignancy transformation assay on human cells.&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.11.20.469412" rel="alternate" title="Artificial Intelligence uncovers carcinogenic human metabolites (11 tweets)"/><category term="Bioinformatics"/><published>2021-11-21T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.11.17.468872</id><title>A3D Database: Structure-based Protein Aggregation Predictions for the Human Proteome (9 tweets)</title><updated>2021-11-22T12:05:39.955449+00:00</updated><author><name>Aleksandra Elzbieta Badaczewska-Dawid</name></author><author><name>Javier Garcia-Pardo</name></author><author><name>Aleksander Kuriata</name></author><author><name>Jordi Pujols</name></author><author><name>Salvador Ventura</name></author><author><name>Sebastian Kmiecik</name></author><content>&lt;p&gt;Motivation: Protein aggregation is associated with highly debilitating human disorders and constitutes a major bottleneck for producing therapeutic proteins. Our knowledge of the human protein structures repertoire has dramatically increased with the recent development of the AlphaFold (AF) deep-learning method. This structural information can be used to understand better protein aggregation properties and the rational design of protein solubility. This article uses the Aggrescan3D (A3D) tool to compute the structure-based aggregation predictions for the human proteome and make the predictions available in a database form. Results: Here, we present the A3D Database, in which we analyze the AF-predicted human protein structures (for over 17 thousand non-membrane proteins) in terms of their aggregation properties using the A3D tool. Each entry of the A3D Database provides a detailed analysis of the structure-based aggregation propensity computed with A3D. The A3D Database implements simple but useful graphical tools for visualizing and interpreting protein structure datasets. We discuss case studies illustrating how the database could be used to analyze physiologically relevant proteins. Furthermore, the database enables testing the influence of user-selected mutations on protein solubility and stability, all integrated into a user-friendly interface. Availability and implementation: A3D Database is freely available at: http://biocomp.chem.uw.edu.pl/A3D2/hproteome&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.11.17.468872" rel="alternate" title="A3D Database: Structure-based Protein Aggregation Predictions for the Human Proteome (9 tweets)"/><category term="Bioinformatics"/><published>2021-11-19T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.11.15.468653</id><title>Deep embedding and alignment of protein sequences (8 tweets)</title><updated>2021-11-22T12:05:39.955595+00:00</updated><author><name>Felipe Llinares-LÃ³pez</name></author><author><name>Quentin Berthet</name></author><author><name>Mathieu Blondel</name></author><author><name>Olivier Teboul</name></author><author><name>Jean-Philippe Vert</name></author><content>&lt;p&gt;Protein sequence alignment is a key component of most bioinformatics pipelines to study the structures and functions of proteins. Aligning highly divergent sequences remains, however, a difficult task that current algorithms often fail to perform accurately, leaving many proteins or open reading frames poorly annotated. Here, we leverage recent advances in deep learning for language modelling and differentiable programming to propose DEDAL, a flexible model to align protein sequences and detect homologs. DEDAL is a machine learning-based model that learns to align sequences by observing large datasets of raw protein sequences and of correct alignments. Once trained, we show that DEDAL improves by up to two- or three-fold the alignment correctness over existing methods on remote homologs, and better discriminates remote homologs from evolutionarily unrelated sequences, paving the way to improvements on many downstream tasks relying on sequence alignment in structural and functional genomics.&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.11.15.468653" rel="alternate" title="Deep embedding and alignment of protein sequences (8 tweets)"/><category term="Bioinformatics"/><published>2021-11-15T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.11.15.468572</id><title>Hypoxia classifier for transcriptome datasets (7 tweets)</title><updated>2021-11-22T12:05:39.955729+00:00</updated><author><name>Laura Puente-Santamaria</name></author><author><name>Lucia Sanchez-Gonzalez</name></author><author><name>Ricardo Ramos-Ruiz</name></author><author><name>Luis del Peso</name></author><content>&lt;p&gt;Molecular gene signatures are useful tools to characterize the physiological state of cell populations according to their gene expression profiles. However, most molecular gene signatures have been developed under a very limited set of conditions and cell types, and are often restricted to a set of gene identities linked to an event or biological process, therefore making necessary to develop and test additional procedures for its application to new data.&lt;/p&gt;&lt;p&gt;Focusing on the transcriptional response to hypoxia, we aimed to generate widely applicable classifiers capable of detecting hypoxic samples while maintaining transparency and ease of use and interpretation. Here we describe several tree-based classifiers sourced from the results of a meta-analysis of 69 differential expression datasets which included 425 individual RNA-seq experiments from 33 different human cell types exposed to different degrees of hypoxia (0.1-5%O&lt;sub&gt;2&lt;/sub&gt;) for a time spanning between 2 and 48h.&lt;/p&gt;&lt;p&gt;These decision trees include both the identities of genes key in the response to hypoxia and defined quantitative boundaries, allowing for the classification of individual samples without needing a control or normoxic reference. Despite their simplicity and ease of use, these classifiers achieve over 95% accuracy in cross validation and over 80% accuracy when applied to additional challenging datasets. Moreover, the explicit structure of the trees allowed for the identification of relevant biological features in cases where prediction was not accurate. Finally, we demonstrate that the classifiers can be applied to spatial gene expression data to identify hypoxic regions within histological sections. Although we have focused on the identification of hypoxia, this method can be applied to detect activation of other processes or cellular states.&lt;/p&gt;&lt;sec&gt;&lt;title&gt;Highlights&lt;/title&gt;&lt;list list-type="bullet"&gt;&lt;list-item&gt;&lt;p&gt;Description of a method to generate simple tree-based gene signatures that combine gene identity and expression.&lt;/p&gt;&lt;/list-item&gt;&lt;list-item&gt;&lt;p&gt;Tree-based gene signatures can be easily applied for accurate absolute classification of samples and regions in spatial gene expression data.&lt;/p&gt;&lt;/list-item&gt;&lt;list-item&gt;&lt;p&gt;The explicit structure of the classifiers permits the intuitive interpretation of classification allowing for novel biological insights.&lt;/p&gt;&lt;/list-item&gt;&lt;/list&gt;&lt;/sec&gt;</content><link href="https://doi.org/10.1101/2021.11.15.468572" rel="alternate" title="Hypoxia classifier for transcriptome datasets (7 tweets)"/><category term="Bioinformatics"/><published>2021-11-15T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.11.17.468921</id><title>Structural comparative modeling of multi-domain Î”F508 CFTR (6 tweets)</title><updated>2021-11-22T12:05:39.955853+00:00</updated><author><name>Eli Fritz McDonald</name></author><author><name>Hope Woods</name></author><author><name>Shannon Smith</name></author><author><name>Minsoo Kim</name></author><author><name>Clara T. Schoeder</name></author><author><name>Lars Plate</name></author><author><name>Jens Meiler</name></author><content>&lt;p&gt;Cystic Fibrosis (CF) is a common genetic disease caused by mutations in the Cystic Fibrosis Transmembrane Conductance Regulator (CFTR), an epithelial anion channel expressed in several vital organs. Absence of functional CFTR results in imbalanced osmotic equilibrium and subsequent mucus build up in the lungs - which increases the risk of infection and eventually causes death. CFTR is an ATP binding cassette (ABC) transporter composed of two transmembrane domains (TMDs), two nucleotide binding domains (NBDs), and an unstructured regulatory domain. The most prevalent patient mutation is the deletion of F508 (Î”F508), making Î”F508 CFTR the primary target for current FDA approved CF therapies. However, no experimental multi-domain Î”F508 CFTR structure has been determined and few studies have modeled Î”F508 using multi-domain WT CFTR structures. Here, we used cryo-EM density data and Rosetta comparative modeling (RosettaCM) to compare a Î”F508 model with published experimental data on CFTR NBD1 thermodynamics. We then apply this modeling method to generate multi-domain WT and Î”F508 CFTR structural models. These models demonstrate the destabilizing effects of Î”F508 on NBD1 and the NBD1/TMD interface in both the closed and open conformation of CFTR. Furthermore, we modeled Î”F508/R1070W and Î”F508 bound to a the CFTR corrector VX-809. Our models reveal the stabilizing effects of R1070W and VX-809 on multi-domain models of Î”F508 CFTR and pave the way for rational design of additional drugs that target Î”F508 CFTR for treatment of CF.&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.11.17.468921" rel="alternate" title="Structural comparative modeling of multi-domain Î”F508 CFTR (6 tweets)"/><category term="Bioinformatics"/><published>2021-11-19T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.11.13.468488</id><title>Single-sample proteome enrichment enables missing protein recovery and phenotype association (5 tweets)</title><updated>2021-11-22T12:05:39.955994+00:00</updated><author><name>Bertrand Jern Han Wong</name></author><author><name>Weijia Kong</name></author><author><name>Wilson Wen Bin Goh</name></author><content>&lt;p&gt;Proteomic studies characterize the protein composition of complex biological samples. Despite recent developments in mass spectrometry instrumentation and computational tools, low proteome coverage remains a challenge. To address this, we present Proteome Support Vector Enrichment (PROSE), a fast, scalable, and effective pipeline for scoring protein identifications based on gene co-expression matrices. Using a simple set of observed proteins as input, PROSE gauges the relative importance of proteins in the phenotype. The resultant enrichment scores are interpretable and stable, corresponding well to the source phenotype, thus enabling reproducible recovery of missing proteins. We further demonstrate its utility via reanalysis of the Cancer Cell Line Encyclopedia (CCLE) proteomic data, with prediction of oncogenic dependencies and identification of well-defined regulatory modules. PROSE is available as a user-friendly Python module from &lt;ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://github.com/bwbio/PROSE"&gt;https://github.com/bwbio/PROSE&lt;/ext-link&gt;.&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.11.13.468488" rel="alternate" title="Single-sample proteome enrichment enables missing protein recovery and phenotype association (5 tweets)"/><category term="Bioinformatics"/><published>2021-11-15T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.11.18.468957</id><title>TIS transformer: Re-annotation of the human proteome using deep learning (5 tweets)</title><updated>2021-11-22T12:05:39.956113+00:00</updated><author><name>Jim Clauwaert</name></author><author><name>Zahra McVey</name></author><author><name>Ramneek Gupta</name></author><author><name>Gerben Menschaert</name></author><content>&lt;p&gt;The precise detection of translation initiation sites is essential for proteome delineation. In turn, the accurate mapping of the proteome is fundamental in advancing our understanding of biological systems and cellular mechanisms. We propose TIS Transformer, a deep learning model for the determination of translation start sites, based on information embedded in processed transcript nucleotide sequences. Through the application of deep learning techniques first designed for natural language processing tasks, we have developed an approach that achieves state-of-the-art performances on the prediction of translation initiation sites. TIS Transformer utilizes the FAVOR+ algorithm for attention calculation, enabling processing of full transcript sequences by the model. Analysis of input importance revealed TIS Transformer's ability to detect key features of translation, such as translation stop sites and reading frames. Furthermore, we demonstrate TIS Transformer's ability to detect multiple peptides on a transcript, and peptides encoded by short Open Reading Frames (sORFs), either alongside a canonical coding sequence or in long non-coding RNAs. Using a cross-validation scheme, we apply TIS Transformer to re-annotate the full human transcriptome.&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.11.18.468957" rel="alternate" title="TIS transformer: Re-annotation of the human proteome using deep learning (5 tweets)"/><category term="Bioinformatics"/><published>2021-11-19T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.11.18.467517</id><title>Semi-supervised single-cell cross-modality translation using Polarbear (4 tweets)</title><updated>2021-11-22T12:05:39.956464+00:00</updated><author><name>Ran Zhang</name></author><author><name>Laetitia Meng-Papaxanthos</name></author><author><name>Jean-Philippe Vert</name></author><author><name>William Stafford Noble</name></author><content>&lt;p&gt;The emergence of single-cell co-assays enables us to learn to translate between single-cell modalities, potentially offering valuable insights from datasets where only one modality is available. However, the sparsity of single-cell measurements and the limited number of cells measured in typical co-assay datasets impedes the power of cross-modality translation. Here, we propose Polarbear, a semi-supervised translation framework to predict cross-modality profiles that is trained using a combination of co-assay data and traditional "single-assay" data. Polarbear uses single-assay and co-assay data to train an autoencoder for each modality and then uses just the co-assay data to train a translator between the embedded representations learned by the autoencoders. With this approach, Polarbear is able to translate between modalities with improved accuracy relative to state-of-the-art translation techniques. As an added benefit of the training procedure, we show that Polarbear also produces a matching of cells across modalities.&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.11.18.467517" rel="alternate" title="Semi-supervised single-cell cross-modality translation using Polarbear (4 tweets)"/><category term="Bioinformatics"/><published>2021-11-19T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.11.15.467961</id><title>Extending and using anatomical vocabularies in the Stimulating Peripheral Activity to Relieve Conditions (SPARC) project (4 tweets)</title><updated>2021-11-22T12:05:39.956713+00:00</updated><author><name>Monique C. Surles - Zeigler</name></author><author><name>Troy Sincomb</name></author><author><name>Thomas H. Gillespie</name></author><author><name>Bernard de Bono</name></author><author><name>Jacqueline Bresnahan</name></author><author><name>Gary M. Mawe</name></author><author><name>Jeffrey S. Grethe</name></author><author><name>Susan Tappan</name></author><author><name>Maci Heal</name></author><author><name>Maryann E. Martone</name></author><content>&lt;p&gt;The Stimulating Peripheral Activity to Relieve Conditions (SPARC) program is a US National Institutes of Health-funded effort to improve our understanding of the neural circuitry of the autonomic nervous system in support of bioelectronic medicine. As part of this effort, the SPARC project is generating multi-species, multimodal data, models, simulations, and anatomical maps supported by a comprehensive knowledge base of autonomic circuitry. To facilitate the organization of and integration across multi-faceted SPARC data and models, SPARC is implementing the FAIR data principles to ensure that all SPARC products are findable, accessible, interoperable, and reusable. We are therefore annotating and describing all products with a common FAIR vocabulary. The SPARC Vocabulary is built from a set of community ontologies covering major domains relevant to SPARC, including anatomy, physiology, experimental techniques, and molecules. The SPARC Vocabulary is incorporated into tools researchers use to segment and annotate their data, facilitating the application of these ontologies for annotation of research data. However, since investigators perform deep annotations on experimental data, not all terms and relationships are available in community ontologies. We therefore implemented a term management and vocabulary extension pipeline where SPARC researchers may extend the SPARC Vocabulary using InterLex, an online vocabulary management system. To ensure the quality of contributed terms, we have set up a curated term request and review pipeline specifically for anatomical terms involving expert review. Accepted terms are added to the SPARC Vocabulary and, when appropriate, contributed back to community ontologies to enhance autonomic nervous system coverage. Here, we provide an overview of the SPARC Vocabulary, the infrastructure and process for implementing the term management and review pipeline. In an analysis of &amp;gt; 300 anatomical contributed terms, the majority represented composite terms that necessitated combining terms within and across existing ontologies. Although these terms are not good candidates for community ontologies, they can be linked to structures contained within these ontologies. We conclude that the term request pipeline serves as a useful adjunct to community ontologies for annotating experimental data and increases the FAIRness of SPARC data.&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.11.15.467961" rel="alternate" title="Extending and using anatomical vocabularies in the Stimulating Peripheral Activity to Relieve Conditions (SPARC) project (4 tweets)"/><category term="Bioinformatics"/><published>2021-11-19T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.11.15.468399</id><title>The effect of sequencing and assembly on the inference of horizontal gene transfer on chromosomal and plasmid phylogenies (4 tweets)</title><updated>2021-11-22T12:05:39.957000+00:00</updated><author><name>Jana S. Huisman</name></author><author><name>Timothy G. Vaughan</name></author><author><name>Adrian Egli</name></author><author><name>Sarah Tschudin-Sutter</name></author><author><name>Tanja Stadler</name></author><author><name>Sebastian Bonhoeffer</name></author><content>&lt;p&gt;The spread of antibiotic resistance genes on plasmids is a threat to human and animal health. Phylogenies of bacteria and their plasmids contain clues regarding the frequency of plasmid transfer events, as well as the co-evolution of plasmids and their hosts. However, whole genome sequencing data from diverse ecological or clinical bacterial samples is rarely used to study plasmid phylogenies and resistance gene transfer. This is partially due to the difficulty to extract plasmids from short-read sequencing data. Here, we use both short- and long-read sequencing data of 24 clinical extended-spectrum &lt;italic&gt;Î²&lt;/italic&gt;-lactamase producing &lt;italic&gt;Escherichia coli&lt;/italic&gt; to estimate chromosomal and plasmid phylogenies. We compare the impact of different sequencing and assembly methodologies on these phylogenies and on the inference of horizontal gene transfer. We find chromosomal phylogenies can be estimated robustly with all methods, whereas plasmid phylogenies have more variable topology and branch lengths across the methods used. Specifically, hybrid methods that use long reads to resolve short-read assemblies (HybridSPAdes and Unicycler) perform better than those that started from long-reads during assembly graph generation (Canu). In contrast, the inference of plasmid and antibiotic resistance gene transfer using a parsimony-based criterion is mostly robust to the choice of sequencing and assembly method.&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.11.15.468399" rel="alternate" title="The effect of sequencing and assembly on the inference of horizontal gene transfer on chromosomal and plasmid phylogenies (4 tweets)"/><category term="Bioinformatics"/><published>2021-11-15T00:00:00+00:00</published></entry></feed>
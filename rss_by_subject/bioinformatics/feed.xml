<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>https://front-matter.io/</id><title>Popular bioinformatics preprints posted in the last week</title><updated>2021-11-08T11:02:17.721539+00:00</updated><author><name>Martin Fenner</name><email>martin@front-matter.io</email></author><link href="https://front-matter.io" rel="alternate"/><link href="https://front-matter.io/bioinformatics/feed.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="0.9.0">python-feedgen</generator><entry><id>https://doi.org/10.1101/2021.11.02.466953</id><title>Population genomics analysis with RAD, reprised: STACKS 2 (23 tweets)</title><updated>2021-11-08T11:02:17.722002+00:00</updated><author><name>Angel G Rivera-Colon</name></author><author><name>Julian M Catchen</name></author><content>&lt;p&gt;Restriction enzymes have been one of the primary tools in the population genetics toolkit for fifty years, being coupled with each new generation of technology to provide a more detailed view into the genetics of natural populations. Restriction site-Associated DNA protocols, which joined enzymes with short-read sequencing technology have democratized the field of population genomics, providing a means to assay the underlying alleles in scores of populations. More than ten years on, the technique has been widely applied across the tree of life and served as the basis for many different analysis techniques. Here, we provide a detailed protocol to conduct a RAD analysis from experimental design to de novo analysis -- including parameter optimization -- as well as reference-based analysis, all in STACKS version 2, which is designed to work with paired-end reads to assemble RAD loci up to 1000 nucleotides in length. The protocol focuses on major points of friction in the molecular approaches and downstream analysis, with special attention given to validating experimental analyses. Finally, the protocol provides several points of departure for further analysis.&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.11.02.466953" rel="alternate" title="Population genomics analysis with RAD, reprised: STACKS 2 (23 tweets)"/><category term="Bioinformatics"/><published>2021-11-04T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.10.29.466473</id><title>Multi-attribute Glycan Identification and FDR Control for Glycoproteomics (18 tweets)</title><updated>2021-11-08T11:02:17.722298+00:00</updated><author><name>Daniel A. Polasky</name></author><author><name>Daniel J. Geiszler</name></author><author><name>Fengchao Yu</name></author><author><name>Alexey I. Nesvizhskii</name></author><content>&lt;p&gt;Rapidly improving methods for glycoproteomics have enabled increasingly large-scale analyses of complex glycopeptide samples, but annotating the resulting mass spectrometry data with high confidence remains a major bottleneck. We recently introduced a fast and sensitive glycoproteomics search method in our MSFragger search engine, which reports glycopeptides as a combination of a peptide sequence and the mass of the attached glycan. In samples with complex glycosylation patterns, converting this mass to a specific glycan composition is not straightforward, however, as many glycans have similar or identical masses. Here, we have developed a new method for determining the glycan composition of N-linked glycopeptides fragmented by collision or hybrid activation that uses multiple sources of information from the spectrum, including observed glycan B- (oxonium) and Y-type ions and mass and precursor monoisotopic selection errors to discriminate between possible glycan candidates. Combined with false discovery rate estimation for the glycan assignment, we show this method is capable of specifically and sensitively identifying glycans in complex glycopeptide analyses and effectively controls the rate of false glycan assignments. The new method has been incorporated into the PTM-Shepherd modification analysis tool to work directly with the MSFragger glyco search in the FragPipe graphical user interface, providing a complete computational pipeline for annotation of N-glycopeptide spectra with FDR control of both peptide and glycan components that is both sensitive and robust against false identifications.&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.10.29.466473" rel="alternate" title="Multi-attribute Glycan Identification and FDR Control for Glycoproteomics (18 tweets)"/><category term="Bioinformatics"/><published>2021-11-01T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.11.03.467086</id><title>RNA splicing analysis using heterogeneous and large RNA-seq datasets (13 tweets)</title><updated>2021-11-08T11:02:17.722617+00:00</updated><author><name>Jorge Vaquero-Garcia</name></author><author><name>Joseph K. Aicher</name></author><author><name>Paul Jewell</name></author><author><name>Matthew R. Gazzara</name></author><author><name>Caleb M. Radens</name></author><author><name>Anupama Jha</name></author><author><name>Christopher J. Green</name></author><author><name>Scott S. Norton</name></author><author><name>Nicholas F. Lahens</name></author><author><name>Gregory R. Grant</name></author><author><name>Yoseph Barash</name></author><content>&lt;p&gt;The ubiquity of RNA-seq has led to many methods that use RNA-seq data to analyze variations in RNA splicing. However, available methods are not well suited for handling heterogeneous and large datasets. Such datasets scale to thousands of samples across dozens of experimental conditions, exhibit increased variability compared to biological replicates, and involve thousands of unannotated splice variants resulting in increased transcriptome complexity. We describe here a suite of algorithms and tools implemented in the MAJIQ v2 package to address challenges in detection, quantification, and visualization of splicing variations from such datasets. Using both large scale synthetic data and GTEx v8 as benchmark datasets, we demonstrate that the approaches in MAJIQ v2 outperform existing methods. We then apply MAJIQ v2 package to analyze differential splicing across 2,335 samples from 13 brain subregions, demonstrating its ability to offer new insights into brain subregion-specific splicing regulation.&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.11.03.467086" rel="alternate" title="RNA splicing analysis using heterogeneous and large RNA-seq datasets (13 tweets)"/><category term="Bioinformatics"/><published>2021-11-03T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.11.04.467355</id><title>Toward optimal fingerprint indexing for large scale genomics (11 tweets)</title><updated>2021-11-08T11:02:17.723823+00:00</updated><author><name>Clement Agret</name></author><author><name>Bastien Cazaux</name></author><author><name>Antoine Limasset</name></author><content>&lt;p&gt;Motivation: To keep up with the scale of genomic databases, several methods rely on local sensitive hashing methods to efficiently find potential matches within large genome collections. Existing solutions rely on Minhash or Hyperloglog fingerprints and require reading the whole index to perform a query. Such solutions can not be considered scalable with the growing amount of documents to index. Results: We present NIQKI, a novel structure using well-designed fingerprints that lead to theoretical and practical query time improvements, outperforming state-of-the-art by orders of magnitude. Our contribution is threefold. First, we generalize the concept of Hyperminhash fingerprints in (h,m)-HMH fingerprints that can be tuned to present the lowest false positive rate given the expected sub-sampling applied. Second, we provide a structure able to index any kind of fingerprints based on inverted indexes that provide optimal queries, namely linear with the size of the output. Third, we implemented these approaches in a tool dubbed NIQKI that can index and calculate pairwise distances for over one million bacterial genomes from GenBank in a matter of days on a small cluster. We show that our approach can be orders of magnitude faster than state-of-the-art with comparable precision. We believe that this approach can lead to tremendous improvement allowing fast query, scaling on extensive genomic databases. Availability and implementation: We wrote the NIQKI index as an open-source C++ library under the AGPL3 license available at https://github.com/Malfoy/ NIQKI. It is designed as a user-friendly tool and comes along with usage sample&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.11.04.467355" rel="alternate" title="Toward optimal fingerprint indexing for large scale genomics (11 tweets)"/><category term="Bioinformatics"/><published>2021-11-05T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.11.04.467289</id><title>ProDCoNN-server: a web server for protein sequence prediction and design from a three-dimensional structure (6 tweets)</title><updated>2021-11-08T11:02:17.724210+00:00</updated><author><name>Yuan Zhang</name></author><author><name>Arunima Mandal</name></author><author><name>Kevin Cui</name></author><author><name>Xiuwen Liu</name></author><author><name>Jinfeng Zhang</name></author><content>&lt;p&gt;We present ProDCoNN-server, a web server for protein sequence design and prediction from a given protein structure. The server is based on a previously developed deep learning model for protein design, ProDCoNN, which achieved state-of-the-art performance when tested on large numbers of test proteins and benchmark datasets. The prediction is very fast compared with other protein sequence prediction servers - it takes only a few minutes for a query protein on average. Two models could be selected for different purposes: BBO for full sequence prediction, extendable for multiple sequence generation, and BBS for single position prediction with the type of other residues known. ProDCoNN-server outputs the predicted sequence and the probability matrix for each amino acid at each predicted residue. The probability matrix can also be visualized as a sequence logos figure (BBO) or probability distribution plot (BBS). The server is available at: https://prodconn.stat.fsu.edu/.&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.11.04.467289" rel="alternate" title="ProDCoNN-server: a web server for protein sequence prediction and design from a three-dimensional structure (6 tweets)"/><category term="Bioinformatics"/><published>2021-11-05T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.11.02.467032</id><title>KinasePhos 3.0: Redesign and Expansion of the Prediction on Kinase-specific Phosphorylation Sites (5 tweets)</title><updated>2021-11-08T11:02:17.724548+00:00</updated><author><name>Renfei Ma</name></author><author><name>Shangfu Li</name></author><author><name>Wenshuo Li</name></author><author><name>Lantian Yao</name></author><author><name>Hsien-Da Huang</name></author><author><name>Tzong-Yi Lee</name></author><content>&lt;p&gt;The purpose of this work is to enhance KinasePhos, a machine-learning-based kinase-specific phosphorylation site prediction tool. Experimentally verified kinase-specific phosphorylation data were collected from PhosphoSitePlus, UniProt, GPS 5.0, and Phospho.ELM. In total, 41,421 experimentally verified kinase-specific phosphorylation sites were identified. A total of 1380 unique kinases were identified, including 753 with existing classification information from KinBase and the remaining 627 annotated by building a phylogenetic tree. Based on this kinase classification, a total of 771 predictive models were built at the individual, family, and group levels, using at least 15 experimentally verified substrate sites in positive training datasets. The improved models were observed to be more effective than other prediction tools. For example, the prediction of sites phosphorylated by the Akt, CKT, and PKA families had accuracies of 94.5%, 92.5%, and 90.0%, respectively. The average prediction accuracy for all 771 models was 87.2%. For enhancing interpretability, the Shapley additive explanations (SHAP) method was employed to assess feature importance. The web interface of KinasePhos 3.0 has been redesigned with the goal of providing comprehensive annotations of kinase-specific phosphorylation sites on multiple proteins. Additionally, considering the large scale of phosphoproteomic data, a downloadable prediction tool is available at https://awi.cuhk.edu.cn/KinasePhos/index.html or https://github.com/tom-209/KinasePhos-3.0-executable-file.&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.11.02.467032" rel="alternate" title="KinasePhos 3.0: Redesign and Expansion of the Prediction on Kinase-specific Phosphorylation Sites (5 tweets)"/><category term="Bioinformatics"/><published>2021-11-04T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.11.05.467356</id><title>A large-scale genome-based survey of acidophilic Bacteria suggests that genome streamlining is an adaption for life at low pH (5 tweets)</title><updated>2021-11-08T11:02:17.724874+00:00</updated><author><name>Diego Nahuel Cortez</name></author><author><name>Gonzalo Andres Neira</name></author><author><name>Carolina Mabel Gonzalez</name></author><author><name>Eva Marilyn Vergara</name></author><author><name>David S Holmes</name></author><content>&lt;p&gt;Genome streamlining theory suggests that reduction of microbial genome size optimizes energy utilization in stressful environments. Although this hypothesis has been explored in several cases of low nutrient (oligotrophic) and high temperature environments, little work has been carried out on microorganisms from low pH environments and what has been reported is inconclusive. In this study, we performed a large-scale comparative genomics investigation of more than 260 bacterial high-quality genome sequences of acidophiles, together with genomes of their closest phylogenetic relatives that live at circum-neutral pH. A statistically supported correlation is reported between reduction of genome size and decreasing pH that we demonstrate is due to gene loss and reduced gene sizes. This trend is independent from other genome size constraints such as temperature and G+C content. Genome streamlining in the evolution of acidophilic Bacteria is thus supported by our results. Analyses of predicted COG categories and subcellular location predictions indicate that acidophiles have a lower representation of genes encoding extra-cellular proteins, signal transduction mechanisms and proteins with unknown function, but are enriched in inner membrane proteins, chaperones, basic metabolism, and core cellular functions. Contrary to other reports for genome streamlining, there was no significant change in paralog frequencies across pH. However, a detailed analysis of COG categories revealed a higher proportion of genes in acidophiles in the following categories: 'Replication and repair', 'Amino acid transport' and 'Intracellular trafficking'. This study brings increasing clarity regarding genomic adaptations of acidophiles to life at low pH while putting elements such as the reduction of average gene size under the spotlight of streamlining theory.&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.11.05.467356" rel="alternate" title="A large-scale genome-based survey of acidophilic Bacteria suggests that genome streamlining is an adaption for life at low pH (5 tweets)"/><category term="Bioinformatics"/><published>2021-11-06T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.11.01.466686</id><title>A low-resource reliable pipeline to democratize multi-modal connectome estimation and analysis (5 tweets)</title><updated>2021-11-08T11:02:17.725194+00:00</updated><author><name>Ross Lawrence</name></author><author><name>Alex Loftus</name></author><author><name>Gregory Kiar</name></author><author><name>Eric W. Bridgeford</name></author><author><name>William Gray Roncal</name></author><author><name>Vikram Chandrashekhar</name></author><author><name>Disa Mhembere</name></author><author><name>Sephira Ryman</name></author><author><name>Xi-Nian Zuo</name></author><author><name>Daniel S. Margulies</name></author><author><name>R. Cameron Craddock</name></author><author><name>Carey E. Priebe</name></author><author><name>Rex Jung</name></author><author><name>Vince D. Calhoun</name></author><author><name>Brian Caffo</name></author><author><name>Randal Burns</name></author><author><name>Michael P. Milham</name></author><author><name>Joshua T. Vogelstein</name></author><author><name> </name></author><content>&lt;p&gt;Connectomics—the study of brain networks—provides a unique and valuable opportunity to study the brain. However, research in human connectomics, accomplished via Magnetic Resonance Imaging (MRI), is a resource-intensive practice: typical analysis routines require impactful decision making and significant computational capabilities. Mitigating these issues requires the development of low-resource, easy to use, and flexible pipelines which can be applied across data with variable collection parameters. In response to these challenges, we have developed the MRI to Graphs (&lt;monospace&gt;m2g&lt;/monospace&gt;) pipeline. &lt;monospace&gt;m2g&lt;/monospace&gt; leverages functional and diffusion datasets to estimate connectomes reliably. To illustrate, &lt;monospace&gt;m2g&lt;/monospace&gt; was used to process MRI data from 35 different studies (≈6,000 scans) from 15 sites without any manual intervention or parameter tuning. Every single scan yielded an estimated connectome that followed established properties, such as stronger ipsilateral than contralateral connections in structural connectomes, and stronger homotopic than heterotopic correlations in functional connectomes. Moreover, the connectomes generated by &lt;monospace&gt;m2g&lt;/monospace&gt; are more similar within individuals than between them, suggesting that &lt;monospace&gt;m2g&lt;/monospace&gt; preserves biological variability. &lt;monospace&gt;m2g&lt;/monospace&gt; is portable, and can run on a single CPU with 16 GB of RAM in less than a couple hours, or be deployed on the cloud using its docker container. All code is available on &lt;ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://neurodata.io/mri/"&gt;https://neurodata.io/mri/&lt;/ext-link&gt;.&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.11.01.466686" rel="alternate" title="A low-resource reliable pipeline to democratize multi-modal connectome estimation and analysis (5 tweets)"/><category term="Bioinformatics"/><published>2021-11-03T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.11.03.467111</id><title>Estimating the Designability of Protein Structures (4 tweets)</title><updated>2021-11-08T11:02:17.725648+00:00</updated><author><name>Feng Pan</name></author><author><name>Yuan Zhang</name></author><author><name>Xiuwen Liu</name></author><author><name>Jinfeng Zhang</name></author><content>&lt;p&gt;The total number of amino acid sequences that can fold to a target protein structure, known as "designability", is a fundamental property of proteins that contributes to their structure and function robustness. The highly designable structures always have higher thermodynamic stability, mutational stability, fast folding, regular secondary structures, and tertiary symmetries. Although it has been studied on lattice models for very short chains by exhaustive enumeration, it remains a challenge to estimate the designable quantitatively for real proteins. In this study, we designed a new deep neural network model that samples protein sequences given a backbone structure using sequential Monte Carlo method. The sampled sequences with proper weights were used to estimate the designability of several real proteins. The designed sequences were also tested using the latest AlphaFold2 and RoseTTAFold to confirm their foldabilities. We report this as the first study to estimate the designability of real proteins.&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.11.03.467111" rel="alternate" title="Estimating the Designability of Protein Structures (4 tweets)"/><category term="Bioinformatics"/><published>2021-11-04T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.11.02.466942</id><title>Validation analysis of EMDB entries (4 tweets)</title><updated>2021-11-08T11:02:17.725958+00:00</updated><author><name>Zhe Wang</name></author><author><name>Ardan Patwardhan</name></author><author><name>Gerard J Kleywegt</name></author><content>&lt;p&gt;The Electron Microscopy Data Bank (EMDB) is the central archive of the electron cryo-microscopy (cryo-EM) community for storing and disseminating volume maps and tomograms. With input from the community, EMDB has developed new resources for validation of cryo-EM structures, focussing on the quality of the volume data alone and that of the fit of any models, themselves archived in the Protein Data Bank (PDB), to the volume data. Based on recommendations from community experts, the validation resources are developed in a three-tiered system. Tier 1 covers an extensive and evolving set of validation metrics, including tried and tested as well as more experimental ones, which are calculated for all EMDB entries and presented in the Validation Analysis (VA) web resource. This system is particularly useful for cryo-EM experts, both to validate individual structures and to assess the utility of new validation metrics. Tier 2 comprises a subset of the validation metrics covered by the VA resource that have been subjected to extensive testing and are considered to be useful for specialists as well as non-specialists. These metrics are presented on the entry-specific web pages for the entire archive on the EMDB website. As more experience is gained with the metrics included in the VA resource, it is expected that consensus will emerge in the community regarding a subset that is suitable for inclusion in the tier 2 system. Tier 3, finally, consists of the validation reports and servers that are produced by the Worldwide Protein Data Bank (wwPDB) Consortium. Successful metrics from tier 2 will be proposed for inclusion in the wwPDB validation pipeline and reports. We describe the details of the new resource, with an emphasis on the tier 1 system. The output of all three tiers is publicly available, either through the EMDB website (tiers 1 and 2) or through the wwPDB ftp sites (tier 3), although the content of all three will evolve over time (fastest for tier 1 and slowest for tier 3). It is our hope that these validation resources will help the cryo-EM community to get a better understanding of the quality, and the best ways to assess the quality of cryo-EM structures in EMDB and PDB.&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.11.02.466942" rel="alternate" title="Validation analysis of EMDB entries (4 tweets)"/><category term="Bioinformatics"/><published>2021-11-04T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.11.04.467271</id><title>decoupleR: Ensemble of computational methods to infer biological activities from omics data (3 tweets)</title><updated>2021-11-08T11:02:17.726245+00:00</updated><author><name>Pau Badia-i-Mompel</name></author><author><name>Jesús Vélez</name></author><author><name>Jana Braunger</name></author><author><name>Celina Geiss</name></author><author><name>Daniel Dimitrov</name></author><author><name>Sophia Müller-Dott</name></author><author><name>Petr Taus</name></author><author><name>Aurelien Dugourd</name></author><author><name>Christian Haydar Holland</name></author><author><name>Ricardo Omar Ramírez Flores</name></author><author><name>Julio Saez-Rodriguez</name></author><content>&lt;p&gt;Summary: Many methods allow us to extract biological activities from omics data using information from prior knowledge resources, reducing the dimensionality for increased statistical power and better interpretability. Here, we present decoupleR, a Bioconductor package containing computational methods to extract these activities within a unified framework. decoupleR allows us to flexibly run any method with a given resource, including methods that leverage mode of regulation and weights of interactions. Using decoupleR, we evaluated the performance of methods on transcriptomic and phospho-proteomic perturbation experiments. Our findings suggest that simple linear models and the consensus score across methods perform better than other methods at predicting perturbed regulators.
Availability and Implementation: decoupleR is open source available in Bioconductor (https://www.bioconductor.org/packages/release/bioc/html/decoupleR.html). The code to reproduce the results is in Github (https://github.com/saezlab/decoupleR_manuscript) and the data in Zenodo (https://zenodo.org/record/5645208).&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.11.04.467271" rel="alternate" title="decoupleR: Ensemble of computational methods to infer biological activities from omics data (3 tweets)"/><category term="Bioinformatics"/><published>2021-11-04T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.11.01.466837</id><title>Comparison of Oxidative and Hypoxic Stress Responsive Genes from Meta-Analysis of Public Transcriptomes (3 tweets)</title><updated>2021-11-08T11:02:17.726651+00:00</updated><author><name>Takayuki Suzuki</name></author><author><name>Yoko Ono</name></author><author><name>Hidemasa Bono</name></author><content>&lt;p&gt;Analysis of RNA-sequencing (RNA-seq) data is an effective means to analyze the gene expression levels under specific conditions and discover new biological knowledge. More than 74000 ex-perimental series with RNA-seq have been stored in public databases as of October 20, 2021. Since this huge amount of expression data accumulated from past studies is a promising source of new biological insights, we focused on a meta-analysis of 1783 runs of RNA-seq data under the conditions of two types of stresses: oxidative stress (OS) and hypoxia. The collected RNA-seq data of OS were organized as the OS dataset to retrieve and analyze differentially expressed genes (DEGs). The OS-induced DEGs were compared with the hypoxia-induced DEGs retrieved from a previous study. The results from the meta-analysis of OS transcriptomes revealed two genes, CRIP1 and CRIP3, which were particularly downregulated, suggesting a relationship be-tween OS and zinc homeostasis. The comparison between meta-analysis of OS and hypoxia showed that several genes were differentially expressed under both stress conditions, and it was inferred that the downregulation of cell cycle-related genes is a mutual biological process in both OS and hypoxia.&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.11.01.466837" rel="alternate" title="Comparison of Oxidative and Hypoxic Stress Responsive Genes from Meta-Analysis of Public Transcriptomes (3 tweets)"/><category term="Bioinformatics"/><published>2021-11-04T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.11.02.466801</id><title>Estimated limits of organism-specific training for epitope prediction (3 tweets)</title><updated>2021-11-08T11:02:17.735233+00:00</updated><author><name>Jodie Ashford</name></author><author><name>Felipe Campelo</name></author><content>&lt;p&gt;Background: The identification of linear B-cell epitopes remains an important task in the development of vaccines, therapeutic antibodies and several diagnostic tests. Machine learning predictors are trained to flag potential epitope candidates for experimental validation and currently, most predictors are trained as generalist models using large, heterogeneous data sets. Recently, organism-specific training has been shown to improve prediction performance for data-rich organisms. Unfortunately, for most organisms, large volumes of validated epitope data are not yet available. This article investigates the limits of organism-specific training for epitope prediction. It explores the validity of organism-specific training for data-poor organisms by examining how the size of the training data set affects prediction performance. It also compares the performance of organism-specific training under simulated data-poor conditions to that of models trained using traditional large heterogeneous and hybrid data sets.
Results: This work shows how models trained on small organism-specific data sets can outperform  similar models trained on (potentially much larger) heterogeneous and mixed data sets. The results reported indicate that as few as 20 labelled peptides from a given pathogen can be sufficient to generate models that outperform widely-used predictors from the literature, which are trained on heterogeneous data. Models trained using more than about 100 to 150 organism-specific peptides perform consistently better than most generalist models across a wide variety of performance measures, and in some cases can even approach the performance of organism-specific models trained on considerably larger data sets.
Conclusions: Organism-specific training improves linear B-cell epitope prediction performance even in situations when only small training sets are available, which opens new possibilities for the development of bespoke, high-performance predictive models when studying data-poor organisms such as emerging or neglected pathogens.&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.11.02.466801" rel="alternate" title="Estimated limits of organism-specific training for epitope prediction (3 tweets)"/><category term="Bioinformatics"/><published>2021-11-04T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.11.03.467049</id><title>Meta-Analysis of cortical inhibitory interneurons markers landscape and their performances in scRNA-seq studies. (3 tweets)</title><updated>2021-11-08T11:02:17.735468+00:00</updated><author><name>Lorenzo Martini</name></author><author><name>Roberta Bardini</name></author><author><name>Stefano Di Carlo</name></author><content>&lt;p&gt;The mammalian cortex contains a great variety of neuronal cells. In particular, GABAergic interneurons, which play a major role in neuronal circuit function, exhibit an extraordinary diversity of cell types. In this regard, single-cell RNA-seq analysis is crucial to study cellular heterogeneity. To identify and analyze rare cell types, it is necessary to reliably label cells through known markers. In this way, all the related studies are dependent on the quality of the employed marker genes. Therefore, in this work, we investigate how a set of chosen inhibitory interneurons markers perform. The gene set consists of both immunohistochemistry-derived genes and single-cell RNA-seq taxonomy ones. We employed various human and mouse datasets of the brain cortex, consequently processed with the Monocle3 pipeline. We defined  metrics based on the relations between unsupervised cluster results and the marker expression. Specifically, we calculated the specificity, the fraction of cells expressing, and some metrics derived from decision tree analysis like entropy gain and impurity reduction. The results highlighted the strong reliability of some markers but also the low quality of others. More interestingly, though, a correlation emerges between the general performances of the genes set and the experimental quality of the datasets. Therefore, the proposed method allows evaluating the quality of a dataset in relation to its reliability regarding the inhibitory interneurons cellular heterogeneity study.&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.11.03.467049" rel="alternate" title="Meta-Analysis of cortical inhibitory interneurons markers landscape and their performances in scRNA-seq studies. (3 tweets)"/><category term="Bioinformatics"/><published>2021-11-04T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.11.02.467030</id><title>SPCS: A Spatial and Pattern Combined Smoothing Method of Spatial Transcriptomic Expression (3 tweets)</title><updated>2021-11-08T11:02:17.735811+00:00</updated><author><name>Yusong Liu</name></author><author><name>Tongxin Wang</name></author><author><name>Ben Duggan</name></author><author><name>Kun Huang</name></author><author><name>Jie Zhang</name></author><author><name>Xiufen Ye</name></author><author><name>Travis S. Johnson</name></author><content>&lt;p&gt;The recently developed spatial transcriptomics (ST) technique has made it possible to view spatial transcriptional heterogeneity in a high throughput manner. It is based on highly multiplexed sequence analysis and uses barcodes to split the sequenced reads into respective tissue locations. However, this type of sequencing technique suffers from high noise and drop-out events in the data, which makes smoothing a necessary step before performing downstream analysis. Traditional smoothing methods used in the similar single cell RNA sequencing (scRNA-seq) data are one-factor methods that can only utilize associations in transcriptome space. Since they do not account for associations in the Euclidean space, i.e. tissue location distances on the ST slide, these one-factor methods cannot take full advantage of all the knowledge in ST data. In this study, we present a novel two-factor smoothing technique, Spatial and Pattern Combined Smoothing (SPCS), that employs k-nearest neighbor technique to utilize associations from transcriptome and Euclidean space from the ST data. By performing SPCS on 10 ST slides from pancreatic ductal adenocarcinoma (PDAC), smoothed ST slides have better separability, partition accuracy, and biological interpretability than the ones smoothed by pre-existing one-factor smoothing methods. Source code of SPCS is provided in Github (&lt;ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://github.com/Usos/SPCS"&gt;https://github.com/Usos/SPCS&lt;/ext-link&gt;).&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.11.02.467030" rel="alternate" title="SPCS: A Spatial and Pattern Combined Smoothing Method of Spatial Transcriptomic Expression (3 tweets)"/><category term="Bioinformatics"/><published>2021-11-04T00:00:00+00:00</published></entry></feed>
<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><id>https://front-matter.io/</id><title>Popular BioRxiv neuroscience preprints posted in the last week</title><updated>2021-06-21T07:09:23.816545+00:00</updated><author><name>Martin Fenner</name><email>martin@front-matter.io</email></author><link href="https://front-matter.io" rel="alternate"/><link href="https://front-matter.io/neuroscience/feed.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="0.9.0">python-feedgen</generator><entry><id>https://doi.org/10.1101/2021.06.18.448989</id><title>The functional specialization of visual cortex emerges from training parallel pathways with self-supervised predictive learning (91 tweets)</title><updated>2021-06-21T07:09:23.816910+00:00</updated><author><name>Shahab Bakhtiari</name></author><author><name>Patrick Mineault</name></author><author><name>Timothy Lillicrap</name></author><author><name>Christopher Pack</name></author><author><name>Blake Richards</name></author><content>&lt;p&gt;The visual system of mammals is comprised of parallel, hierarchical specialized pathways. Different pathways are specialized in so far as they use representations that are more suitable for supporting specific downstream behaviours. In particular, the clearest example is the specialization of the ventral ('what') and dorsal ('where') pathways of the visual cortex. These two pathways support behaviours related to visual recognition and movement, respectively. To-date, deep neural networks have mostly been used as models of the ventral, recognition pathway. However, it is unknown whether both pathways can be modelled with a single deep ANN. Here, we ask whether a single model with a single loss function can capture the properties of both the ventral and the dorsal pathways. We explore this question using data from mice, who like other mammals, have specialized pathways that appear to support recognition and movement behaviours. We show that when we train a deep neural network architecture with two parallel pathways using a self-supervised predictive loss function, we can outperform other models in fitting mouse visual cortex. Moreover, we can model both the dorsal and ventral pathways. These results demonstrate that a self-supervised predictive learning approach applied to parallel pathway architectures can account for some of the functional specialization seen in mammalian visual systems.&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.06.18.448989" rel="alternate" title="The functional specialization of visual cortex emerges from training parallel pathways with self-supervised predictive learning (91 tweets)"/><category term="Neuroscience"/><published>2021-06-18T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.06.16.448638</id><title>State transitions in the statistically stable place cell population are determined by visual change (48 tweets)</title><updated>2021-06-21T07:09:23.817248+00:00</updated><author><name>Sander Tanni</name></author><author><name>William de Cothi</name></author><author><name>Caswell Barry</name></author><content>&lt;p&gt;The hippocampus plays a central role in mammalian navigation and memory, yet an implementational understanding of the rules that govern the formation of individual place fields and the spatial-statistics of the population as a whole are lacking. We analysed large numbers of CA1 place fields recorded while rats foraged in different-sized environments up to 8.75 m&lt;sup&gt;2&lt;/sup&gt;. We found that place cell propensities to form fields were proportional to open-field area, gamma-distributed, and conserved across environments. The properties of place fields varied positionally with a denser distribution of smaller fields near boundaries. Remarkably, the variation in field sizes and densities exactly countered each other, such that the population-level statistics were constant both within and between environments. Using a virtual reality replica of the environment, we showed that this variable rate of transition through the statistically stable place cell population was matched to change in the animals’ visual scenes.&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.06.16.448638" rel="alternate" title="State transitions in the statistically stable place cell population are determined by visual change (48 tweets)"/><category term="Neuroscience"/><published>2021-06-17T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.06.16.448755</id><title>Neural event segmentation of continuous experience in human infants (34 tweets)</title><updated>2021-06-21T07:09:23.817436+00:00</updated><author><name>Tristan S. Yates</name></author><author><name>Lena J. Skalaban</name></author><author><name>Cameron T. Ellis</name></author><author><name>Angelika J. Bracher</name></author><author><name>Christopher Baldassano</name></author><author><name>Nicholas B. Turk-Browne</name></author><content>&lt;p&gt;Although sensory input is continuous, we perceive and remember discrete events. Event segmentation has been studied extensively in adults, but little is known about how the youngest minds experience the world. The main impediment to studying event segmentation in infants has been a reliance on explicit parsing tasks that are not possible at this age. fMRI has recently proven successful at measuring adult event segmentation during task-free, naturalistic perception. Applied to infants, this could reveal the nature of their event segmentation, from low-level sensory transients to high-level cognitive boundaries. We collected fMRI data from 25 adults and 25 infants less than one year of age watching the same short movie. Neural events were defined by the stability of voxel activity patterns. In adults, we replicated a hierarchical gradient of event timescales, from shorter events in early visual regions to longer events in later visual and narrative regions. In infants, however, longer events were found throughout the brain, including in a second dataset. Infant event structure fit adult data and vice versa, but adult behavioral boundaries were differently expressed in adult and infant brains. These findings have implications for the nature of infant experience and cognition.&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.06.16.448755" rel="alternate" title="Neural event segmentation of continuous experience in human infants (34 tweets)"/><category term="Neuroscience"/><published>2021-06-16T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.06.17.448812</id><title>Cellular and molecular signatures of in vivo GABAergic neurotransmission in the human brain (19 tweets)</title><updated>2021-06-21T07:09:23.817627+00:00</updated><author><name>PB Lukow</name></author><author><name>D Martins</name></author><author><name>M Veronese</name></author><author><name>AC Vernon</name></author><author><name>P McGuire</name></author><author><name>FE Turkheimer</name></author><author><name>G Modinos</name></author><content>&lt;p&gt;Diverse GABAergic interneuron microcircuits orchestrate information processing in the brain. Understanding the cellular and molecular composition of these microcircuits, and whether these can be imaged by available non-invasive &lt;italic&gt;in vivo&lt;/italic&gt; methods is crucial for the study of GABAergic neurotransmission in health and disease. Here, we use human gene expression data and state-of-the-art imaging transcriptomics to uncover co-expression patterns between GABA&lt;sub&gt;A&lt;/sub&gt; receptor subunits and interneuron subtype-specific markers, and to decode the cellular and molecular signatures of gold-standard GABA PET radiotracers, [&lt;sup&gt;11&lt;/sup&gt;C]Ro15-4513 and [&lt;sup&gt;11&lt;/sup&gt;C]flumazenil. We find that the interneuron marker somatostatin is co-expressed with GABA&lt;sub&gt;A&lt;/sub&gt; receptor-subunit genes &lt;italic&gt;GABRA5&lt;/italic&gt; and &lt;italic&gt;GABRA2&lt;/italic&gt;, and their distribution maps onto [&lt;sup&gt;11&lt;/sup&gt;C]Ro15-4513 binding &lt;italic&gt;in vivo&lt;/italic&gt;. In contrast, the interneuron marker parvalbumin co-expressed with more predominant GABA&lt;sub&gt;A&lt;/sub&gt; receptor subunits (&lt;italic&gt;GABRA1, GABRB2&lt;/italic&gt; and &lt;italic&gt;GABRG2&lt;/italic&gt;), and their distribution tracks [&lt;sup&gt;11&lt;/sup&gt;C]flumazenil binding &lt;italic&gt;in vivo&lt;/italic&gt;. These results have important implications for the non-invasive study of GABAergic microcircuit dysfunction in psychiatric conditions.&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.06.17.448812" rel="alternate" title="Cellular and molecular signatures of in vivo GABAergic neurotransmission in the human brain (19 tweets)"/><category term="Neuroscience"/><published>2021-06-17T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.06.16.448764</id><title>The Cost of Untracked Diversity in Brain-Imaging Prediction (13 tweets)</title><updated>2021-06-21T07:09:23.817818+00:00</updated><author><name>Oualid Benkarim</name></author><author><name>Casey Paquola</name></author><author><name>Bo-yong Park</name></author><author><name>Valeria Kebets</name></author><author><name>Seok-Jun Hong</name></author><author><name>Reinder Vos de Wael</name></author><author><name>Shaoshi Zhang</name></author><author><name>B.T. Thomas Yeo</name></author><author><name>Michael Eickenberg</name></author><author><name>Tian Ge</name></author><author><name>Jean-Baptiste Poline</name></author><author><name>Boris Bernhardt</name></author><author><name>Danilo Bzdok</name></author><content>&lt;p&gt;Brain-imaging research enjoys increasing adoption of supervised machine learning for singlesubject disease classification. Yet, the success of these algorithms likely depends on population diversity, including demographic differences and other factors that may be outside of primary scientific interest. Here, we capitalize on &lt;italic&gt;propensity scores&lt;/italic&gt; as a composite confound index to quantify diversity due to major sources of population stratification. We delineate the impact of population heterogeneity on the predictive accuracy and pattern stability in two separate clinical cohorts: the Autism Brain Imaging Data Exchange (ABIDE, n=297) and the Healthy Brain Network (HBN, n=551). Across various analysis scenarios, our results uncover the extent to which cross-validated prediction performances are interlocked with diversity. The instability of extracted brain patterns attributable to diversity is located preferentially to the default mode network. Our collective findings highlight the limitations of prevailing deconfounding practices in mitigating the full consequences of population diversity.&lt;/p&gt;</content><link href="https://doi.org/10.1101/2021.06.16.448764" rel="alternate" title="The Cost of Untracked Diversity in Brain-Imaging Prediction (13 tweets)"/><category term="Neuroscience"/><published>2021-06-17T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.06.15.448526</id><title>Attrition Rate in Infant fNIRS Research: A Meta-Analysis (11 tweets)</title><updated>2021-06-21T07:09:23.818047+00:00</updated><author><name>Sori Baek</name></author><author><name>Sabrina Marques</name></author><author><name>Kennedy Casey</name></author><author><name>Meghan Testerman</name></author><author><name>Felicia McGill</name></author><author><name>Lauren Emberson</name></author><content>&lt;p&gt;Understanding the trends and predictors of attrition rate, or the proportion of collected data that is excluded from the final analyses, is important for accurate research planning, assessing data integrity, and ensuring generalizability. In this pre-registered meta-analysis, we reviewed 182 publications in infant (0-24 months) functional near-infrared spectroscopy (fNIRS) research published from 1998 to April 9, 2020 and investigated the trends and predictors of attrition. The average attrition rate was 34.23% among 272 experiments across all 182 publications. Among a subset of 136 experiments which reported the specific reasons of subject exclusion, 21.50% of the attrition were infant-driven while 14.21% were signal-driven. Subject characteristics (e.g., age) and study design (e.g., fNIRS cap configuration, block/trial design, and stimulus type) predicted the total and subject-driven attrition rates, suggesting that modifying the recruitment pool or the study design can meaningfully reduce the attrition rate in infant fNIRS research. Based on the findings, we established guidelines on reporting the attrition rate for scientific transparency and made recommendations to minimize the attrition rates. We also launched an attrition rate calculator (&lt;bold&gt;LINK&lt;/bold&gt;) to aid with research planning. This research can facilitate developmental cognitive neuroscientists in their quest toward increasingly rigorous and representative research.&lt;/p&gt;&lt;sec&gt;&lt;title&gt;Highlights&lt;/title&gt;&lt;list list-type="bullet"&gt;&lt;list-item&gt;&lt;p&gt;Average attrition rate in infant fNIRS research is 34.23%&lt;/p&gt;&lt;/list-item&gt;&lt;list-item&gt;&lt;p&gt;21.50% of the attrition are infant-driven (e.g., inattentiveness) while 14.21% are signal-driven (e.g., poor optical contact)&lt;/p&gt;&lt;/list-item&gt;&lt;list-item&gt;&lt;p&gt;Subject characteristics (e.g., age) and study design (e.g., fNIRS cap configuration, block/trial design, and stimulus type) predict the total and infant-driven attrition rates&lt;/p&gt;&lt;/list-item&gt;&lt;list-item&gt;&lt;p&gt;Modifying the recruitment pool or the study design can meaningfully reduce the attrition rate in infant fNIRS research&lt;/p&gt;&lt;/list-item&gt;&lt;/list&gt;&lt;/sec&gt;</content><link href="https://doi.org/10.1101/2021.06.15.448526" rel="alternate" title="Attrition Rate in Infant fNIRS Research: A Meta-Analysis (11 tweets)"/><category term="Neuroscience"/><published>2021-06-16T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.06.15.448519</id><title>The locus of recognition memory signals in human cortex depends on the complexity of the memory representations (9 tweets)</title><updated>2021-06-21T07:09:23.818232+00:00</updated><author><name>D. Merika W. Sanders</name></author><author><name>Rosemary A. Cowell</name></author><content>&lt;p&gt;Representational theories predict that brain regions contribute to cognition according to the information they represent (e.g., simple versus complex), contradicting the traditional notion that brain regions are specialized for cognitive functions (e.g., perception versus memory). In support of representational accounts, substantial evidence now attests that the Medial Temporal Lobe (MTL) is not specialized solely for long-term declarative memory, but underpins other functions including perception and future-imagining for complex stimuli and events. However, a complementary prediction has been less well explored, namely that the cortical locus of declarative memory may fall outside the MTL if the to-be-remembered content is sufficiently simple. Specifically, the locus should coincide with the optimal neural code for the representations being retrieved. To test this prediction, we manipulated the complexity of the to-be-remembered representations in a recognition memory task. First, participants in the scanner viewed novel 3D objects and scenes, and we used multivariate analyses to identify regions in the ventral visual-MTL pathway that preferentially coded for either simple features of the stimuli, or complex conjunctions of those features. Next, in a separate scan, we tested recognition memory for these stimuli and performed neuroimaging contrasts that revealed two memory signals ‒ feature memory and conjunction memory. Feature memory signals were found in visual cortex, while conjunction memory signals emerged in MTL. Further, the regions optimally representing features via preferential feature-coding coincided with those exhibiting feature memory signals. These findings suggest that representational content, rather than cognitive function, is the primary organizing principle in the ventral visual-MTL pathway.&lt;/p&gt;&lt;sec&gt;&lt;title&gt;Significance Statement&lt;/title&gt;&lt;p&gt;Representational theories of cognition propose that the primary principle driving how memory and perception map onto the brain is the type of information that each brain region contains. A key prediction is that a classic “memory region”, the medial temporal lobe (MTL), should underpin cognitive tasks beyond memory, if the task stimuli necessitate representations of MTL-appropriate information (e.g., complex objects and scenes). Substantial evidence now supports this prediction. However, the complementary prediction ‒ that declarative memory should engage areas outside of MTL if the stimuli are sufficiently simple ‒ is less thoroughly explored. We provide neuroimaging evidence that extra-MTL regions support long-term recognition memory for simple information, and that the location of a memory signal depends on its information content.&lt;/p&gt;&lt;/sec&gt;</content><link href="https://doi.org/10.1101/2021.06.15.448519" rel="alternate" title="The locus of recognition memory signals in human cortex depends on the complexity of the memory representations (9 tweets)"/><category term="Neuroscience"/><published>2021-06-15T00:00:00+00:00</published></entry><entry><id>https://doi.org/10.1101/2021.06.14.448305</id><title>Analyzing the differences in olfactory bulb mitral cell spiking with ortho- and retronasal stimulation (5 tweets)</title><updated>2021-06-21T07:09:23.818388+00:00</updated><author><name>Michelle F. Craft</name></author><author><name>Andrea K. Barreiro</name></author><author><name>Shree Hari Gautam</name></author><author><name>Woodrow L. Shew</name></author><author><name>Cheng Ly</name></author><content>&lt;p&gt;The majority of olfaction studies focus on orthonasal stimulation where odors enter via the front nasal cavity, while retronasal olfaction, where odors enter the rear of the nasal cavity during feeding, is understudied. The processing of retronasal odors via coordinated spiking of neurons in the olfactory bulb (&lt;bold&gt;OB&lt;/bold&gt;) is largely unknown. To this end, we use multi-electrode array &lt;italic&gt;in vivo&lt;/italic&gt; recordings of rat OB mitral cells (&lt;bold&gt;MC&lt;/bold&gt;) in response to a food odor with both modes of stimulation, and find significant differences in evoked firing rates and spike count covariances (i.e., noise correlations). To better understand these differences, we develop a single-compartment biophysical OB model that is able to reproduce key properties of important OB cell types. Prior experiments in olfactory receptor neurons (&lt;bold&gt;ORN&lt;/bold&gt;) showed retro stimulation yields slower and spatially smaller ORN inputs than with ortho, yet whether this is consequential for OB activity remains unknown. Indeed with these specifications for ORN inputs, our OB model captures the trends in our OB data. We also analyze how first and second order ORN input statistics dynamically transfer to MC spiking statistics with a phenomenological linear-nonlinear filter model, and find that retro inputs result in larger temporal filters than ortho inputs. Finally, our models show that the temporal profile of ORN is crucial for capturing our data and is thus a distinguishing feature between ortho and retro stimulation, even at the OB. Using data-driven modeling, we detail how ORN inputs result in differences in OB dynamics and MC spiking statistics. These differences may ultimately shape how ortho and retro odors are coded.&lt;/p&gt;&lt;sec&gt;&lt;title&gt;Author summary&lt;/title&gt;&lt;p&gt;Olfaction is a key sense for many cognitive and behavioral tasks, and is particularly unique because odors can naturally enter the nasal cavity from the front or rear, i.e., ortho- and retro-nasal, respectively. Yet little is known about the differences in coordinated spiking in the olfactory bulb with ortho versus retro stimulation, let alone how these different modes of olfaction may alter coding of odors. We simultaneously record many cells in rat olfactory bulb to assess the differences in spiking statistics, and develop a biophysical olfactory bulb network model to study the reasons for these differences. Using theoretical and computational methods, we find that the olfactory bulb transfers input statistics differently for retro stimulation relative to ortho stimulation. Furthermore, our models show that the temporal profile of inputs is crucial for capturing our data and is thus a distinguishing feature between ortho and retro stimulation, even at the olfactory bulb. Understanding the spiking dynamics of the olfactory bulb with both ortho and retro stimulation is a key step for ultimately understanding how the brain codes odors with different modes of olfaction.&lt;/p&gt;&lt;/sec&gt;</content><link href="https://doi.org/10.1101/2021.06.14.448305" rel="alternate" title="Analyzing the differences in olfactory bulb mitral cell spiking with ortho- and retronasal stimulation (5 tweets)"/><category term="Neuroscience"/><published>2021-06-14T00:00:00+00:00</published></entry></feed>